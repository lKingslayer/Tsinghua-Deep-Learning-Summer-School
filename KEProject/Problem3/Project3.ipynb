{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "./init.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-48160fbd15d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./init.so\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: ./init.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import ctypes\n",
    "\n",
    "ll = ctypes.cdll.LoadLibrary   \n",
    "lib = ll(\"./init.so\")\n",
    "\n",
    "\n",
    "class Config(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.L1_flag = True\n",
    "        self.hidden_sizeE = 100\n",
    "        self.hidden_sizeR = 100\n",
    "        self.nbatches = 100\n",
    "        self.entity = 0\n",
    "        self.relation = 0\n",
    "        self.trainTimes = 3000\n",
    "        self.margin = 1.0\n",
    "        \n",
    "        self.rel_init = None\n",
    "        self.ent_init = None\n",
    "\n",
    "class TransRModel(object):\n",
    "\n",
    "    def __init__(self, config, ent_init = None, rel_init = None):\n",
    "\n",
    "        entity_total = config.entity\n",
    "        relation_total = config.relation\n",
    "        batch_size = config.batch_size\n",
    "        sizeE = config.hidden_sizeE\n",
    "        sizeR = config.hidden_sizeR\n",
    "        margin = config.margin\n",
    "        \n",
    "        with tf.name_scope(\"read_inputs\"):\n",
    "            self.pos_h = tf.placeholder(tf.int32, [batch_size])\n",
    "            self.pos_t = tf.placeholder(tf.int32, [batch_size])\n",
    "            self.pos_r = tf.placeholder(tf.int32, [batch_size])\n",
    "            self.neg_h = tf.placeholder(tf.int32, [batch_size])\n",
    "            self.neg_t = tf.placeholder(tf.int32, [batch_size])\n",
    "            self.neg_r = tf.placeholder(tf.int32, [batch_size])\n",
    "\n",
    "        with tf.name_scope(\"embedding\"):\n",
    "            if ent_init != None:\n",
    "                self.ent_embeddings = tf.Variable(np.loadtxt(ent_init), name = \"ent_embedding\", dtype = np.float32)\n",
    "            else:\n",
    "                self.ent_embeddings = tf.get_variable(name = \"ent_embedding\", shape = [entity_total, sizeE], initializer = tf.contrib.layers.xavier_initializer(uniform = False))\n",
    "            if rel_init != None:\n",
    "                self.rel_embeddings = tf.Variable(np.loadtxt(rel_init), name = \"rel_embedding\", dtype = np.float32)\n",
    "            else:\n",
    "                self.rel_embeddings = tf.get_variable(name = \"rel_embedding\", shape = [relation_total, sizeR], initializer = tf.contrib.layers.xavier_initializer(uniform = False))\n",
    "\n",
    "            rel_matrix = np.zeros([relation_total, sizeR * sizeE], dtype = np.float32)\n",
    "            for i in range(relation_total):\n",
    "                for j in range(sizeR):\n",
    "                    for k in range(sizeE):\n",
    "                        if j == k:\n",
    "                            rel_matrix[i][j * sizeE + k] = 1.0\n",
    "            self.rel_matrix = tf.Variable(rel_matrix, name = \"rel_matrix\")\n",
    "        \n",
    "        with tf.name_scope('lookup_embeddings'):\n",
    "            pos_h_e = tf.reshape(tf.nn.embedding_lookup(self.ent_embeddings, self.pos_h), [-1, sizeE, 1])\n",
    "            pos_t_e = tf.reshape(tf.nn.embedding_lookup(self.ent_embeddings, self.pos_t), [-1, sizeE, 1])\n",
    "            pos_r_e = tf.reshape(tf.nn.embedding_lookup(self.rel_embeddings, self.pos_r), [-1, sizeR])\n",
    "            neg_h_e = tf.reshape(tf.nn.embedding_lookup(self.ent_embeddings, self.neg_h), [-1, sizeE, 1])\n",
    "            neg_t_e = tf.reshape(tf.nn.embedding_lookup(self.ent_embeddings, self.neg_t), [-1, sizeE, 1])\n",
    "            neg_r_e = tf.reshape(tf.nn.embedding_lookup(self.rel_embeddings, self.neg_r), [-1, sizeR])\n",
    "            pos_matrix = tf.reshape(tf.nn.embedding_lookup(self.rel_matrix, self.pos_r), [-1, sizeR, sizeE])\n",
    "            neg_matrix = tf.reshape(tf.nn.embedding_lookup(self.rel_matrix, self.neg_r), [-1, sizeR, sizeE])\n",
    "\n",
    "            pos_h_e = tf.nn.l2_normalize(tf.reshape(tf.matmul(pos_matrix, pos_h_e), [-1, sizeR]), 1)\n",
    "            pos_t_e = tf.nn.l2_normalize(tf.reshape(tf.matmul(pos_matrix, pos_t_e), [-1, sizeR]), 1)\n",
    "            neg_h_e = tf.nn.l2_normalize(tf.reshape(tf.matmul(neg_matrix, neg_h_e), [-1, sizeR]), 1)\n",
    "            neg_t_e = tf.nn.l2_normalize(tf.reshape(tf.matmul(neg_matrix, neg_t_e), [-1, sizeR]), 1)\n",
    "\n",
    "\n",
    "        if config.L1_flag:\n",
    "            pos = tf.reduce_sum(abs(pos_h_e + pos_r_e - pos_t_e), 1, keep_dims = True)\n",
    "            neg = tf.reduce_sum(abs(neg_h_e + neg_r_e - neg_t_e), 1, keep_dims = True)\n",
    "            \n",
    "        else:\n",
    "            pos = tf.reduce_sum((pos_h_e + pos_r_e - pos_t_e) ** 2, 1, keep_dims = True)\n",
    "            neg = tf.reduce_sum((neg_h_e + neg_r_e - neg_t_e) ** 2, 1, keep_dims = True)\n",
    "\n",
    "\n",
    "        with tf.name_scope(\"output\"):\n",
    "            self.loss = tf.reduce_sum(tf.maximum(pos - neg + margin, 0))\n",
    "\n",
    "def main(_):\n",
    "    lib.init()\n",
    "    config = Config()\n",
    "    config.relation = lib.getRelationTotal()\n",
    "    config.entity = lib.getEntityTotal()\n",
    "    config.batch_size = lib.getTripleTotal() // config.nbatches\n",
    "\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "        config_gpu = tf.ConfigProto()\n",
    "        config_gpu.gpu_options.allow_growth = True\n",
    "        config_gpu.gpu_options.per_process_gpu_memory_fraction = 0.15\n",
    "        sess = tf.Session()\n",
    "        with sess.as_default():\n",
    "            initializer = tf.contrib.layers.xavier_initializer(uniform = False)\n",
    "            with tf.variable_scope(\"model\", reuse=None, initializer = initializer):\n",
    "                trainModel = TransRModel(config = config)\n",
    "\n",
    "            global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "            optimizer = tf.train.AdamOptimizer(config.learning_rate)\n",
    "            grads_and_vars = optimizer.compute_gradients(trainModel.loss)\n",
    "            train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "            saver = tf.train.Saver()\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "            \n",
    "            def train_step(pos_h_batch, pos_t_batch, pos_r_batch, neg_h_batch, neg_t_batch, neg_r_batch):\n",
    "                feed_dict = {\n",
    "                    trainModel.pos_h: pos_h_batch,\n",
    "                    trainModel.pos_t: pos_t_batch,\n",
    "                    trainModel.pos_r: pos_r_batch,\n",
    "                    trainModel.neg_h: neg_h_batch,\n",
    "                    trainModel.neg_t: neg_t_batch,\n",
    "                    trainModel.neg_r: neg_r_batch\n",
    "                }\n",
    "                _, step, loss = sess.run(\n",
    "                    [train_op, global_step, trainModel.loss], feed_dict)\n",
    "                return loss\n",
    "\n",
    "            ph = np.zeros(config.batch_size, dtype = np.int32)\n",
    "            pt = np.zeros(config.batch_size, dtype = np.int32)\n",
    "            pr = np.zeros(config.batch_size, dtype = np.int32)\n",
    "            nh = np.zeros(config.batch_size, dtype = np.int32)\n",
    "            nt = np.zeros(config.batch_size, dtype = np.int32)\n",
    "            nr = np.zeros(config.batch_size, dtype = np.int32)\n",
    "\n",
    "            ph_addr = ph.__array_interface__['data'][0]\n",
    "            pt_addr = pt.__array_interface__['data'][0]\n",
    "            pr_addr = pr.__array_interface__['data'][0]\n",
    "            nh_addr = nh.__array_interface__['data'][0]\n",
    "            nt_addr = nt.__array_interface__['data'][0]\n",
    "            nr_addr = nr.__array_interface__['data'][0]\n",
    "\n",
    "            for times in range(config.trainTimes):\n",
    "                res = 0.0\n",
    "                for batch in range(config.nbatches):\n",
    "                    lib.getBatch(ph_addr, pt_addr, pr_addr, nh_addr,\n",
    "                                 nt_addr, nr_addr, config.batch_size)\n",
    "                    res += train_step(ph, pt, pr, nh, nt, nr)\n",
    "                    current_step = tf.train.global_step(sess, global_step)\n",
    "                print(times)\n",
    "                print(res)\n",
    "            #saver.save(sess, 'model.vec')\n",
    "            # save the embeddings\n",
    "            f = open(\"entity2vec.txt\", \"w\")\n",
    "            enb = trainModel.ent_embeddings.eval()\n",
    "            for i in enb:\n",
    "                for j in i:\n",
    "                    f.write(\"%f\\t\" % (j))\n",
    "                f.write(\"\\n\")\n",
    "            f.close()\n",
    "\n",
    "            f = open(\"relation2vec.txt\", \"w\")\n",
    "            enb = trainModel.rel_embeddings.eval()\n",
    "            for i in enb:\n",
    "                for j in i:\n",
    "                    f.write(\"%f\\t\" % (j))\n",
    "                f.write(\"\\n\")\n",
    "            f.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
