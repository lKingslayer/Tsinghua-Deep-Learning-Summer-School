{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CogDL for Node Classification on Custom Dataset.\n",
    "\n",
    "This homework focuses on using **CogDL** to do node classification on custom dataset. We first show an example on a small ***corax*** dataset, then the homework requires you to train on the provided ***Aminer*** dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Firstly, let's import necessary libraries.The dataset is stored in *.pkl*, so we need *pickle* to load it. Some necessary functions of **CogDL** are also imported as the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from cogdl.data import Data\n",
    "from cogdl.datasets import build_dataset\n",
    "from cogdl.models import build_model\n",
    "from cogdl.tasks import build_task\n",
    "from cogdl.utils import build_args_from_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Construct a class for your custom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.num_features = data.x.shape[1]\n",
    "        self.num_classes = torch.max(self.data.y).item() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Set default args of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_args():\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    default_dict = {'hidden_size': 16,\n",
    "                    'dropout': 0.5,\n",
    "                    'patience': 100,\n",
    "                    'max_epoch': 500,\n",
    "                    'cpu': not cuda_available,\n",
    "                    'lr': 0.01,\n",
    "                    'weight_decay': 5e-4}\n",
    "    return build_args_from_dict(default_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then we construct our custom dataset based on the features, labels and adjacency. The dataset fed into the **CogDL** shall consist of $x$ for node features, *edge_index* for edges on the graph, $y$ for labels, *train_mask* to identify whether a node belongs to train set or not, *val_mask* to identify whether a node belongs to validation set, and *test_mask* which identifies whether a node belongs to the test set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_custom_dataset():\n",
    "    \n",
    "    f = open(\"corax_features.pkl\",\"rb\")\n",
    "    x_features = pickle.load(f)\n",
    "    f.close()\n",
    "    print(\"number of nodes:\", x_features.shape[0])\n",
    "    print(\"number of node features:\", x_features.shape[1])\n",
    "\n",
    "    f = open(\"corax_labels.pkl\",\"rb\")\n",
    "    x_labels = pickle.load(f)\n",
    "    f.close()\n",
    "    print(\"number of classes:\",x_labels.shape[1])\n",
    "\n",
    "    f = open(\"corax_adj.pkl\",\"rb\")\n",
    "    x_adj = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    edges = x_adj.nonzero()\n",
    "    \n",
    "    x = torch.from_numpy(x_features).float()\n",
    "    y_onehot = torch.from_numpy(x_labels).long()\n",
    "    y = torch.topk(y_onehot,1)[1].squeeze(1)\n",
    "    edge_index = torch.from_numpy(np.array([edges[0],edges[1]])).long()\n",
    "    \n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "    \n",
    "    num_samples = x_labels.shape[0]\n",
    "    idx = list(range(num_samples))\n",
    "    data.train_mask = torch.zeros(num_samples, dtype = torch.bool)\n",
    "    data.train_mask[idx[:-1500]] = True\n",
    "    data.val_mask = torch.zeros(num_samples, dtype = torch.bool)\n",
    "    data.val_mask[idx[-1500:-1000]] = True\n",
    "    data.test_mask = torch.zeros(num_samples, dtype = torch.bool)\n",
    "    data.test_mask[idx[-1000:]] = True\n",
    "    \n",
    "    custom_dataset = CustomDataset(data)\n",
    "\n",
    "    return custom_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we finished all these preparations, we select a task and a model, construct our custom dataset and set the number of layers of your model. Here let's use GCN model for node classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes: 2680\n",
      "number of node features: 302\n",
      "number of classes: 7\n"
     ]
    }
   ],
   "source": [
    "args = get_default_args()\n",
    "args.task = 'node_classification'\n",
    "args.model = 'pyg_gcn'\n",
    "\n",
    "dataset = construct_custom_dataset()\n",
    "\n",
    "args.num_features = dataset.num_features\n",
    "args.num_classes = dataset.num_classes\n",
    "args.num_layers = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally, we shall run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 336, Train: 0.9449, Val: 0.8840:  67%|██████▋   | 333/500 [00:02<00:00, 173.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = build_model(args)\n",
    "task = build_task(args, dataset=dataset, model=model)\n",
    "ret = task.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model shall yield a test accuracy around 0.85 for corax dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Train on Aminer Dataset\n",
    "\n",
    "Apart from the ***corax*** dataset, we also provide the larger ***Aminer*** dataset, whose node features, adjacency, and labels are provided in *Aminer_adj.pkl, Aminer_features.pkl* and *Aminer_labels.pkl*.\n",
    "\n",
    "Your goal is to \n",
    "\n",
    "- 1: build a custom model configuration: select your base model and hyperparameters for your custom model. Better base model or hyperparameter leads to better results.\n",
    "- 2: Run your custom model on ***Aminer*** dataset, you shall randomly select 50,000 nodes for testing and 50,000 for validation.\n",
    "- 3: The homework will be scored based on your code and training results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_aminer_dataset():\n",
    "    #write your code here\n",
    "    f = open(\"Aminer_features.pkl\",\"rb\")\n",
    "    x_features = pickle.load(f)\n",
    "    f.close()\n",
    "    print(\"number of nodes:\", x_features.shape[0])\n",
    "    print(\"number of node features:\", x_features.shape[1])\n",
    "    \n",
    "    f = open(\"Aminer_labels.pkl\",\"rb\")\n",
    "    x_labels = pickle.load(f)\n",
    "    f.close()\n",
    "    print(\"number of classes:\",x_labels.shape[1])\n",
    "\n",
    "    f = open(\"Aminer_adj.pkl\",\"rb\")\n",
    "    x_adj = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    edges = x_adj.nonzero()\n",
    "    \n",
    "    x = torch.from_numpy(x_features).float()\n",
    "    y_onehot = torch.from_numpy(x_labels).long()\n",
    "    y = torch.topk(y_onehot,1)[1].squeeze(1)\n",
    "    edge_index = torch.from_numpy(np.array([edges[0],edges[1]])).long()\n",
    "    \n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "    \n",
    "    num_samples = x_labels.shape[0]\n",
    "    idx = list(range(num_samples))\n",
    "    data.train_mask = torch.zeros(num_samples, dtype = torch.bool)\n",
    "    data.train_mask[idx[:-1500]] = True\n",
    "    data.val_mask = torch.zeros(num_samples, dtype = torch.bool)\n",
    "    data.val_mask[idx[-1500:-1000]] = True\n",
    "    data.test_mask = torch.zeros(num_samples, dtype = torch.bool)\n",
    "    data.test_mask[idx[-1000:]] = True\n",
    "    \n",
    "    aminer_dataset = CustomDataset(data)\n",
    "\n",
    "    \n",
    "    return aminer_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_args():\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    # select your custom_dict here\n",
    "    custom_dict = {'hidden_size': 16,\n",
    "                    'dropout': 0.5,\n",
    "                    'patience': 100,\n",
    "                    'max_epoch': 500,\n",
    "                    'cpu': not cuda_available,\n",
    "                    'lr': 0.01,\n",
    "                    'weight_decay': 5e-4}\n",
    "    \n",
    "    return build_args_from_dict(custom_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes: 593486\n",
      "number of node features: 100\n",
      "number of classes: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 499, Train: 0.6262, Val: 0.6420: 100%|██████████| 500/500 [03:46<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# build your own model\n",
    "args = get_custom_args()\n",
    "args.task = 'node_classification'\n",
    "args.model = 'pyg_gcn'\n",
    "\n",
    "dataset = construct_aminer_dataset()\n",
    "\n",
    "args.num_features = dataset.num_features\n",
    "args.num_classes = dataset.num_classes\n",
    "args.num_layers = 3\n",
    "\n",
    "model = build_model(args)\n",
    "task = build_task(args, dataset=dataset, model=model)\n",
    "ret = task.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The test accuracy for your custom model on Aminer dataset is: 0.634"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
